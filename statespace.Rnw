\documentclass[english]{beamer}
\definecolor{links}{HTML}{2A1B81}
\hypersetup{colorlinks,linkcolor=,urlcolor=links}
\usepackage{natbib}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{multicol}
\usepackage{color}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{graphicx}
\let\oldemph=\emph
\newcommand{\todo}[1]{{\color{red} \bf #1}}
\renewcommand{\emph}[1]{{\color{red} {\textbf{#1}}}}
\newcommand{\pkglink}[1]{\href{http://cran.r-project.org/web/packages/#1}{\nolinkurl{#1}}}
\newcommand{\rflink}[1]{\href{https://r-forge.r-project.org/projects/#1/}{\nolinkurl{#1}}}
\newcommand{\fnlink}[2]{\href{http://stat.ethz.ch/R-manual/R-patched/library/#1/html/#2.html}{\nolinkurl{#1:#2}}}
\newcommand{\code}[1]{{\tt #1}}
\newcommand{\ssqobs}{\sigma^2_{\mbox{\small obs}}}
\newcommand{\ssqproc}{\sigma^2_{\mbox{\small proc}}}
\newcommand{\obs}[1]{#1_{\text{\small obs}}}
\newcommand{\obst}[1]{#1_{\text{\small obs}}(t)}
\newcommand{\obstm}[1]{#1_{\text{\small obs}}(t-1)}

\bibliographystyle{notitle}

\usetheme{Frankfurt}
\usecolortheme{dove}
\setbeamercovered{transparent}
\setbeamercolor{description item}{fg=blue}

\usepackage{babel}
\begin{document}

\makeatletter
\def\newblock{\beamer@newblock}
\makeatother 


% http://tex.stackexchange.com/questions/38015/beamer-best-way-to-span-long-enumerations-on-different-frames
\makeatletter
\newenvironment{cenumerate}{%
  \enumerate
  \setcounter{\@enumctr}{\csname saved@\@enumctr\endcsname}%
}{%
  \expandafter\xdef\csname saved@\@enumctr\endcsname{\the\value{\@enumctr}}%
  \endenumerate
}
\newenvironment{cenumerate*}{%
  \enumerate
}{%
  \expandafter\xdef\csname saved@\@enumctr\endcsname{\the\value{\@enumctr}}%
  \endenumerate
}
\makeatother
<<opts,echo=FALSE>>=
require("knitr")
knit_hooks$set(crop=hook_pdfcrop)
opts_chunk$set(fig.width=4,fig.height=4,
               out.width="0.6\\textwidth",
               fig.align="center",
               tidy=FALSE,error=FALSE)
@
<<libs,echo=FALSE,message=FALSE>>=
library(reshape)
library(lattice)
## library(lme4)
## library(plotrix)
library(ggplot2)
theme_set(theme_bw())
source("labfuns.R")
@ 

\title[Stochastic-dynamic estimation]{introduction to Bayesian state space models}
\author{Ben~Bolker}
\institute{McMaster University \\
Departments of Mathematics \& Statistics and Biology}

\date{20 June 2017}
% \pgfdeclareimage[height=0.5cm]{uflogo}{letterhdwm}
% \logo{\pgfuseimage{uflogo}}
\AtBeginSection[]{
  \frame<beamer>{ 
     \frametitle{Outline}   
     \tableofcontents[currentsection] 
   }
 }

\begin{frame}
\titlepage
\end{frame}
% \beamerdefaultoverlayspecification{<+->}

\begin{frame}
\frametitle{Outline}
\tableofcontents{}
\end{frame}

\section{super-quick intro to Bayes}

\subsection{}

\newcommand{\ub}[2]{\underbrace{#1}_{\mbox{\small #2}}}
\begin{frame}
\frametitle{Big picture}
\begin{itemize}
\item use Bayes' rule
\item avoid frequentist contortions
\item integrate prior knowledge
\item make coherent decisions
\item compute hard things
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Bayes rule}

\begin{equation*}
\ub{P(H_i | D)}{posterior}  =  \ub{P(D | H_i)}{likelihood} \ub{P(H_i)}{prior}/ \ub{\sum_j P(H_j) P(D|H_j)}{P(data)}
\end{equation*}

<<bayespic,echo=FALSE,fig.width=8,fig.height=8>>=
r <- 0
d <- acos(r)
scale <- c(0.5,0.3)
npoints <- 100
centre <- c(0.5,0.5)
a <- seq(0, 2 * pi, len = npoints)
m <- matrix(c(scale[1] * cos(a + d/2) + centre[1], 
              scale[2] * cos(a - d/2) + centre[2]), npoints, 2)
e <- 0.05
hyp_pts <- matrix(c(0.37,1.04,
  1+e,0.8+e,
  1,-e,
  0.4,-e,
  -e,0.25),
  byrow=TRUE,ncol=2)
lab.pts <- matrix(c(0.091,0.255,0.597,0.557,
  0.869,0.709,0.549,0.511,
  0.170,0.22,
  ##y
  0.865,0.613,
  0.932,0.698,0.191,0.477,
  0.087,0.277,0.077,0.31),
  ncol=2)
##hyp_pts <- hyp_pts[c(5,1:4),]
## lab.pts <- lab.pts[c(5,1:4),]
## par(mar=c(0.2,0.2,0.2,0.2))
plot(1,1,type="n",xlim=c((-e),1+e),ylim=c(-e,1+e),ann=FALSE,
     xlab="",ylab="",axes=FALSE,xaxs="i",yaxs="i")
box()
polygon(m,col="lightgray",lwd=2)
polygon(c(-e,0.5,0.4,-e),c(0.25,0.5,-e,-e),density=8,angle=0,
        col="darkgray")
lines(m,lwd=2)
segments(rep(0.5,nrow(hyp_pts)),rep(0.5,nrow(hyp_pts)),
         hyp_pts[,1],hyp_pts[,2])
##text(lab.pts[,1],lab.pts[,2],1:10)
for(i in 1:5) {
  r <- 2*i-1
  r2 <- 2*i
  text(lab.pts[r,1],lab.pts[r,2], substitute(H[x],
                                list(x=i)),adj=0,cex=2)
  text(lab.pts[r2,1],lab.pts[r2,2], substitute(D*intersect("","","")*H[x],
                                list(x=i)),adj=0,cex=2)
}
@ 

\end{frame}

\begin{frame}
\frametitle{priors: $P(H_i)$}

\begin{itemize}
\item usually framed as ``prior belief''
\item controversial because subjective
\item if we set all $P(H_i)$ equal, $P(H_i|D) = P(D|H_i)/\sum P(D|H_j)$
(\emph{scaled likelihood})
\item can't really be swept under the rug
\end{itemize}

\end{frame}

\begin{frame}
\frametitle{more on priors}

\begin{itemize}
\item \emph{weak} or \emph{diffuse}: little information
\item \emph{uninformative} or \emph{flat}: no information
\item \emph{improper}: integral diverges (but sometimes OK)
\item weak priors can cause problems with sparse data and/or weakly identifiable models
\item \emph{conjugate} priors: convenient functional forms
\end{itemize}

\end{frame}

<<def_priorpix,echo=FALSE>>=
tmpf <- function(a,b,N=10,minp=0,maxp=1,dp=1e-2,
                 size=15,scaled_prior=TRUE,
                 scaled_lik=TRUE,main="",legpos="left",
                 xlab="probability",ylab="probability/likelihood",
                 xticks=TRUE) {
  pvec = seq(minp,maxp,by=dp)
  likvec = dbinom(N,size=size,prob=pvec)
  prior = dbeta(pvec,a,b) ## 2*(1-pvec)
  ## plot(pvec,prior,type="l",main="prior")
  post = dbeta(pvec,a+N,b+size-N)
  ## prior*likvec/sum(prior*likvec)
  ylab <- "posterior"
  if (scaled_lik) {
    likvec <- likvec/(sum(likvec)*dp)
  }
  matplot(pvec,cbind(likvec,prior,post),
          type="l",xlab=xlab,ylab=ylab,
          col=c(1,2,4),lty=1,main=main,
          axes=FALSE)
  if (xticks) axis(side=1,at=c(0,1))
  box()
  legend(legpos,
         col=c(1,2,4),lty=1,
         c("likelihood","prior","posterior"))
}
@

\begin{frame}
\frametitle{effects of priors}

<<pr1,echo=FALSE,fig.width=7,fig.height=7>>=
par(mfrow=c(2,2),mgp=c(1,0,0),mar=c(2.5,2.5,1,1))
tmpf(1,1,main="flat prior")
tmpf(0.01,10,main=expression("prior prob" %->% 0))
tmpf(10,0.01,main=expression("prior prob" %->% 1))
tmpf(11,6,main="prior = likelihood")
@ 
\end{frame}

\section{Markov chain Monte Carlo}
\subsection{}

\begin{frame}
\frametitle{Markov chain Monte Carlo}
\begin{itemize}
\item \emph{general} method for sampling posterior probability densities
\item construct a Markov chain whose stationary density equals the
  desired posterior probability density
\item avoids computation of Bayes' rule denominator
($\iint P(\bm \theta) \, d \bm\theta$)
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{you won't believe these two MCMC tricks}
\begin{description}
\item[Gibbs sampling] sample parameters one at a time, \\
exploiting conditioning

\item[Rejection sampling] (Metropolis-Hastings): pick new values of parameters at random, then pick a random number to decide whether to keep them
\end{description}
\end{frame}

\begin{frame}
\frametitle{Gibbs sampling}
\newcommand{\prob}{\textrm{Prob}}
Because $\prob(A|B) = \prob(A,B)/\prob(B)$,
%% (x|y) * (y|x) = (x,y)/(x) * (x,y)/(y)
%% (x,y,z)/(x,y) * (x,y,z)/(x,z) * (x,y,z)/(y,z)
we can say
$$
\text{Prob}(A,B,C,\ldots Z) \propto \text{Prob}(A|B,\ldots,Z) 
\cdot \text{Prob}(B|C,\ldots,Z) \cdot \ldots \cdot \prob(Z)
$$
This means that we can sample the conditional probabilities \emph{sequentially} and get the right answer.

\todo{picture of sampling}

\end{frame}

\begin{frame}
\frametitle{Metropolis-Hastings}
Jump, evaluate (prior $\times$ likelihood), decide whether to accept
\begin{equation*}
\frac{\text{Prob}(A)}{\text{Prob}(B)} = %
\frac{P(\text{jump } B \to A) \cdot P(\text{accept }A|B)}%
{P(\text{jump } A \to B) \cdot P(\text{accept }B|A)}
\label{eq:mcmccrit}
\end{equation*}
In the long run our chain will converge to the right distribution
\begin{itemize}
\item \emph{candidate distribution}: anything sensible \\
(bad choices make sampling slow, but not incorrect)
\item \emph{acceptance rule}: $$P(\textrm{accept } \theta_2) =
\textrm{max}\left(1,
\frac{\textrm{Pr}(\theta_2) L(\theta_2)}{\textrm{Pr}(\theta_1) L(\theta_1)}
\right)$$
i.e. ``always accept if $\theta_2$ better: sometimes if $\theta_2$ worse''
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Magic black boxes}
\begin{itemize}
\item Can construct your own, customized samplers \citep{bolk+03c}
\item Use BUGS (Bayesian Inference Using Gibbs Sampling) language (\code{WinBUGS}, \code{OpenBUGS}, \code{JAGS}, \code{NIMBLE})
\item interfaces from R (\href{\code{R2jags} package}{https://CRAN.R-project.org/package=R2jags}) or MATLAB (\url{https://github.com/msteyvers/matjags}).
\end{itemize}
\end{frame}

\section{State-space models}
\subsection{}
\begin{frame}
\frametitle{State space models}
\begin{itemize}
\item address fundamental problem: prob(observations) depends on \emph{unobserved} true values
\item have to deal with/integrate over all possible values (\emph{latent variables})
\item very high-dimensional: brute force fails
\item use the previous two tricks
\end{itemize}
\end{frame}

\begin{frame}[fragile]
\frametitle{BUGS code for the logistic function}
{\small
<<bugsmodel>>=
model <- function() {
  t[1] <- n0    ## initial values ...
  o[1] ~ dnorm(t[1],tau.obs)
  for (i in 2:N) {   ## step through observations ...
     v[i] <- t[i-1]+r*t[i-1]*(1-t[i-1]/K)
     t[i] ~ dnorm(v[i],tau.proc)
     o[i] ~ dnorm(t[i],tau.obs)
  }
  r ~ dunif(0.1,maxr) ## priors ...
  ## rate and scale of gamma    
  K ~ dgamma(0.005,0.005)
  tau.obs ~ dgamma(0.005,0.005)
  tau.proc ~ dgamma(0.005,0.005)
  n0 ~ dgamma(1,n0rate)
}
@
}
\end{frame}

\begin{frame}
  \frametitle{Dependency structure for logistic model}
  \begin{center}
  \includegraphics[height=1.85in]{pix/dynam-DAG}
  \end{center}
\end{frame}

\begin{frame}[fragile]
\frametitle{BUGS vs R}
\begin{itemize}
\item BUGS code is not sequential (!)
\item BUGS is not vectorized (need \code{for} loops)
\item BUGS: \verb+~+ means ``distributed as'' (``stochastic node'') \\
\verb+<-+ means assignment (``logical node'')
\item different distribution names and parameterizations
(e.g. \code{dnorm(mean,prec)} for Normal, \code{dbin(size,prob)}
for binomial): see \cite{lebauer_translating_2013}
\end{itemize}
\end{frame}
  
\begin{frame}
\frametitle{Running JAGS}
\begin{itemize}
  \item \emph{Good news}: JAGS code is (relatively) intuitive
  \item \emph{Bad news}:
    \begin{itemize}
    \item Debugging is hard
    \item Need to figure out how long to run chains \\
      (convergence diagnostics)
    \item Poor mixing
    \item Slow computation
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}
\frametitle{Running JAGS (details)}
\begin{itemize}
\item specify model and priors
\item get model to compile
\item run multiple chains
\begin{itemize}
\item discard \emph{burn-in}
\item thin results
\end{itemize}
\item assess convergence
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Troubleshooting JAGS}
\begin{itemize}
\item simplify model
\item specify initial values explicitly
\item narrow priors and/or fix some parameters
\item run longer and thin more
\end{itemize}
\end{frame}

<<getjags,echo=FALSE,message=FALSE>>=
library(R2jags)
library(coda)
library(lattice)
jagsout <- readRDS("data/jags_model_fit.rds")
@

\begin{frame}[fragile]
\frametitle{Diagnostics example}
\emph{trace plots}: should look like white noise
<<jagstrace,message=FALSE>>=
library(R2jags); library(coda); library(lattice)
xyplot(as.mcmc(jagsout))
@ 
\end{frame}

\begin{frame}[fragile]
\frametitle{Diagnostics example}
\emph{Gelman-Rubin statistic}: want $\hat R < 1.2$
<<jagsdiag>>=
gelman.diag(as.mcmc(jagsout))
@ 
\end{frame}

\begin{frame}
\frametitle{Density plots}
<<jagsens,echo=FALSE,fig.width=7,fig.height=6>>=
densityplot(as.mcmc(jagsout),layout=c(2,2),asp="fill")
@
\end{frame}


\begin{frame}[fragile]
\frametitle{Summary example}
\small
<<getjags0,results="hide",message=FALSE>>=
summary(as.mcmc(jagsout))
@
<<nojags,echo=FALSE>>=
jout <- capture.output(summary(as.mcmc(jagsout)))
@ 
<<printjags,echo=FALSE>>=
cat(jout[10:15],sep="\n")
@ 
\end{frame}

\begin{frame}
\frametitle{Inference from posteriors}
\begin{itemize}
\item point estimates: mean, median (marginal)
\item interval estimates: quantiles, \emph{highest posterior density} (\code{coda::HPDinterval})
\item can summarize any quantity computed from samples \\
(e.g. predictions)
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Further resources}
\begin{itemize}
\item \cite{gelman_bayesian_2013} (fairly hard-core)
\item \cite{hobbs_bayesian_2015} (friendlier, ecologist-focused)
\item \cite{gelman_data_2006} (more regression-focused)
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{The problem with MCMC (\href{https://xkcd.com/303/}{xkcd})}
\includegraphics[height=0.7\textheight]{pix/xkcd_MCMC.png}
\end{frame}

\section[Other approaches]{Other approaches to nonlinear dynamical fitting}
\subsection{}
\begin{frame}
\frametitle{Frequentist alternatives}
\begin{itemize}
\item MCMC is usually Bayesian; \\
opens various cans of worms
\item there are many other related approaches,
some classical
\begin{itemize}
\item expectation-maximization
\item sequential Monte Carlo/particle filters
\citep{Ionides+2006,Doucet+2001,deValpine2004}: R \code{pomp}, \code{NIMBLE} packages, PyMC
\item data cloning \citep{Lele+2007}: R \code{dclone} package
\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Estimation for continuous-time models}
\begin{itemize}
\item Particle methods
\begin{itemize}
\item simulate many trajectories (``particles'') step-by-step
\item at each step, resample particles weighted by likelihood of current location
\end{itemize}
\item Approximate Bayesian computation
\begin{itemize}
\item sample parameters from prior
\item simulate trajectories for each parameter set
\item compute summary statistics (``probes'')
\item save trajectories with summary stats near observed values
\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}
\frametitle{References}
\let\emph\oldemph
\tiny
\bibliography{stochdyn}
\end{frame}

\end{document}
